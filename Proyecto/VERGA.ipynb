{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f1f6d1a92610ac9",
   "metadata": {},
   "source": [
    "Toxic Comment Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd7d7117f45e1d6",
   "metadata": {},
   "source": [
    "Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62251e13d707c4ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T11:50:28.624649Z",
     "start_time": "2025-05-19T11:50:28.615491Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk import FreqDist, bigrams, word_tokenize, classify, NaiveBayesClassifier, ConfusionMatrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import CategorizedPlaintextCorpusReader\n",
    "from nltk.probability import ConditionalFreqDist\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e087d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T10:47:16.126058Z",
     "start_time": "2025-05-19T10:47:15.964658Z"
    }
   },
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7722b403d60fa28a",
   "metadata": {},
   "source": [
    "1. Data Download and Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528121cec364f215",
   "metadata": {},
   "source": [
    "1.1 Loading Data with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89919bed94647f3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:39:52.530305Z",
     "start_time": "2025-05-19T07:39:51.023299Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(train_path, test_path):\n",
    "    df_train = pd.read_csv(train_path)\n",
    "    df_test  = pd.read_csv(test_path)\n",
    "\n",
    "    label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "    df_train['non_toxic'] = (df_train[label_cols].sum(axis=1) == 0).astype(int)\n",
    "\n",
    "    return df_train, df_test\n",
    "\n",
    "df_train, df_test = load_data(\n",
    "    'Dataset/train.csv',\n",
    "    'Dataset/test.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52932bb578eabb9d",
   "metadata": {},
   "source": [
    "1.2 Initial Inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab128bcff0ed9205",
   "metadata": {},
   "source": [
    "Display dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcd32b1fe9dbd9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:39:52.550937Z",
     "start_time": "2025-05-19T07:39:52.547934Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Train shape:\", df_train.shape)\n",
    "print(\"Test shape:\", df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01a1e45b20f14e1",
   "metadata": {},
   "source": [
    "Show first rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6197884840e9f270",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:39:52.613157Z",
     "start_time": "2025-05-19T07:39:52.604642Z"
    }
   },
   "outputs": [],
   "source": [
    "display(df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fac5104794c55e",
   "metadata": {},
   "source": [
    "Null values by column in train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654b1aa6276d9dc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:39:52.702198Z",
     "start_time": "2025-05-19T07:39:52.678176Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df_train.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df27d627c2c0395",
   "metadata": {},
   "source": [
    "Label distribution in train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b480f7af14aaf68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:39:52.796813Z",
     "start_time": "2025-05-19T07:39:52.789637Z"
    }
   },
   "outputs": [],
   "source": [
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate', 'non_toxic']\n",
    "print(df_train[label_cols].sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435f7578e309df57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:39:52.995605Z",
     "start_time": "2025-05-19T07:39:52.838124Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=df_train[label_cols].sum().index, y=df_train[label_cols].sum().values)\n",
    "plt.title('Label distribution')\n",
    "plt.title('Comment Distribution by Label')\n",
    "plt.ylabel('Number of Comments')\n",
    "plt.xlabel('Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53320fafcd18443",
   "metadata": {},
   "source": [
    "2. First Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94881a0101986fc",
   "metadata": {},
   "source": [
    "2.1 Missing Values and Null Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c26d4dd1c74b282",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:39:53.033852Z",
     "start_time": "2025-05-19T07:39:53.009557Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6012d894e6896f99",
   "metadata": {},
   "source": [
    "2.2 Class Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfb35565e86acad",
   "metadata": {},
   "source": [
    "The dataset has six target columns: toxic, severe_toxic, obscene, threat, insult, identity_hate.\n",
    "\n",
    "Display the count and proportion of each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2af2f4e4e09927",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:39:53.089109Z",
     "start_time": "2025-05-19T07:39:53.079229Z"
    }
   },
   "outputs": [],
   "source": [
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate', 'non_toxic']\n",
    "class_counts = df_train[label_cols].sum().sort_values(ascending=False)\n",
    "class_props = class_counts / len(df_train)\n",
    "print(pd.concat([class_counts, class_props], axis=1, keys=['count','proportion']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fa0c639562aeb9",
   "metadata": {},
   "source": [
    "2.3 Comment Length Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95aefa32145a028",
   "metadata": {},
   "source": [
    "Compute length of each comment (in characters and words):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f9f6409bb58223",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:39:53.724413Z",
     "start_time": "2025-05-19T07:39:53.138148Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train['char_count'] = df_train['comment_text'].apply(len)\n",
    "df_train['word_count'] = df_train['comment_text'].apply(lambda x: len(x.split()))\n",
    "display(df_train[['char_count','word_count']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e79011d6cc1a29b",
   "metadata": {},
   "source": [
    "Plot histograms of comment lengths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22be53cb4a3c0297",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:39:53.892039Z",
     "start_time": "2025-05-19T07:39:53.746907Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "df_train['word_count'].hist(bins=50)\n",
    "plt.title('Distribution of Comment Word Counts')\n",
    "plt.xlabel('Word Count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4007cc1923293d",
   "metadata": {},
   "source": [
    "2.4 Sample Comments by Category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef9ed9b221f1b83",
   "metadata": {},
   "source": [
    "Show example comments for each label where the label is 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b378adfcf9cdb73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:39:53.978845Z",
     "start_time": "2025-05-19T07:39:53.943313Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in label_cols:\n",
    "    print(f\"\\nExamples of {col} comments:\")\n",
    "    examples = df_train[df_train[col]==1]['comment_text'].sample(2, random_state=42).tolist()\n",
    "    for ex in examples:\n",
    "        print(\"- \", ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98441ade1d051432",
   "metadata": {},
   "source": [
    "3. Create corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b8f2144eb88bcc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:39:54.362347Z",
     "start_time": "2025-05-19T07:39:54.005849Z"
    }
   },
   "outputs": [],
   "source": [
    "# Crear el directorio principal para almacenar el corpus\n",
    "corpus_dir = 'corpus_by_label'\n",
    "os.makedirs(corpus_dir, exist_ok=True)\n",
    "\n",
    "# Guardar los comentarios en carpetas y archivos separados por etiqueta\n",
    "for label in label_cols:\n",
    "    comments = df_train[df_train[label] == 1]['comment_text'].dropna()\n",
    "\n",
    "    # Crear una carpeta con el nombre de la etiqueta\n",
    "    label_dir = os.path.join(corpus_dir, label)\n",
    "    os.makedirs(label_dir, exist_ok=True)\n",
    "\n",
    "    # Ruta del archivo dentro de la carpeta creada\n",
    "    file_path = os.path.join(label_dir, f\"{label}.txt\")\n",
    "\n",
    "    # Guardar todos los comentarios de la etiqueta en el archivo dentro de su carpeta\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        for comment in comments:\n",
    "            f.write(comment.replace('\\n', ' ') + '\\n')\n",
    "\n",
    "print(f\"Corpus successfully loaded in: {corpus_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96d84175ce0d2c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:39:54.441239Z",
     "start_time": "2025-05-19T07:39:54.376724Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load corpus\n",
    "corpus = CategorizedPlaintextCorpusReader(\n",
    "    corpus_dir,\n",
    "    r'.*\\.txt',\n",
    "    cat_pattern=r\"([^/.]+)/.*\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8eb384cdfa3b83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:39:54.459003Z",
     "start_time": "2025-05-19T07:39:54.455746Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"File IDs:\", corpus.fileids())\n",
    "print(\"Categories:\", corpus.categories())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cfc7d3e9a2b0bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:39:54.490077Z",
     "start_time": "2025-05-19T07:39:54.485378Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Primeras 10 palabras de 'toxic':\")\n",
    "print(corpus.words(categories='toxic')[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf86416",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:40:11.832984Z",
     "start_time": "2025-05-19T07:39:54.545732Z"
    }
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "words = [word.lower() for word in corpus.words()]\n",
    "corpus_norm = [word for word in words if word.isalpha() and word not in stop_words]\n",
    "\n",
    "def normalizer(category):\n",
    "    words = [word.lower() for word in corpus.words(categories=category)]\n",
    "    return [word for word in words if word.isalpha() and word not in stop_words]\n",
    "\n",
    "categories_norm = {\n",
    "    \"identity_hate\": normalizer(\"identity_hate\"),\n",
    "    \"insult\": normalizer(\"insult\"),\n",
    "    \"obscene\": normalizer(\"obscene\"),\n",
    "    \"severe_toxic\": normalizer(\"severe_toxic\"),\n",
    "    \"threat\": normalizer(\"threat\"),\n",
    "    \"toxic\": normalizer(\"toxic\"),\n",
    "    \"non_toxic\": normalizer(\"non_toxic\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a90712",
   "metadata": {},
   "source": [
    "4. Corpus Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c281dc",
   "metadata": {},
   "source": [
    "Number of words and vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b9ebc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:47:00.246572Z",
     "start_time": "2025-05-19T07:46:31.745743Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Word tokens in the corpus: {len(corpus.words())}\")\n",
    "print(f\"Wordforms in the corpus: {len(set(corpus.words()))}\\n\")\n",
    "\n",
    "for category in corpus.categories():\n",
    "    print(f\"{category}:\")\n",
    "    print(f\"Word tokens in {category}: {len(corpus.words(categories=category))}\")\n",
    "    print(f\"Wordforms in {category}: {len(set(corpus.words(categories=category)))}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fbba2941b716c1",
   "metadata": {},
   "source": [
    "Lexical diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d193d865ffd08c9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T08:01:51.413161Z",
     "start_time": "2025-05-19T08:01:35.989823Z"
    }
   },
   "outputs": [],
   "source": [
    "def lexical_diversity(words):\n",
    "    return len(set(words)) / len(words)\n",
    "\n",
    "print(f\"Total corpus lexical diversity: {round(100 * lexical_diversity(corpus.words()), 2)}%\\n\")\n",
    "\n",
    "for category in corpus.categories():\n",
    "    print(f\"{category} lexical diversity: {round(100 * lexical_diversity(corpus.words(categories=category)), 2)}%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8249c5d6b8fd7211",
   "metadata": {},
   "source": [
    "Words length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2cb55067e11b38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T08:50:47.718568Z",
     "start_time": "2025-05-19T08:50:39.576548Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Total corpus length analysis:\\n\")\n",
    "\n",
    "# Create FreqDist of the tokens lenght\n",
    "fd_len = FreqDist(len(w) for w in corpus_norm)\n",
    "\n",
    "# 10 most common sizes\n",
    "print(fd_len.most_common(10))\n",
    "\n",
    "# Most frequent word size and its frequency\n",
    "freq_len = fd_len.max()\n",
    "print(f\"Most common lenght: {freq_len} ({fd_len[freq_len]} words)\")\n",
    "print(f\"Lenght proportion {freq_len}: {round(100 * fd_len.freq(freq_len), 2)}%\")\n",
    "\n",
    "short_tokens = [w for w in corpus_norm if len(w) < freq_len]\n",
    "print(f\"Tokens with length < {freq_len}: {short_tokens[:10]}\")\n",
    "\n",
    "common_tokens = [w for w in corpus_norm if len(w) == freq_len]\n",
    "print(f\"Tokens with length == {freq_len}: {common_tokens[:10]}\")\n",
    "\n",
    "long_tokens = [w for w in corpus_norm if len(w) > freq_len]\n",
    "print(f\"Tokens with length > {freq_len}: {long_tokens[:5]}\")\n",
    "\n",
    "longest_word = max(corpus_norm, key=len)\n",
    "print(f\"The longest word is: '{longest_word[:25]}...' with {len(longest_word)} characters.\")\n",
    "\n",
    "long_words = [w for w in corpus_norm if len(w) > 15]\n",
    "\n",
    "fd_long_words = FreqDist(long_words)\n",
    "print(f\"\\nTotal words longer than 15 characters: {len(long_words)}\")\n",
    "print(f\"Unique words longer than 15 characters: {len(set(long_words))}\\n\")\n",
    "\n",
    "for key, category in categories_norm.items():\n",
    "\n",
    "    print(f\"{key} length analysis :\\n\")\n",
    "\n",
    "    # Create FreqDist of the tokens lenght\n",
    "    fd_len = FreqDist(len(w) for w in category)\n",
    "\n",
    "    # 10 most common sizes\n",
    "    print(fd_len.most_common(10))\n",
    "\n",
    "    # Most frequent word size and its frequency\n",
    "    freq_len = fd_len.max()\n",
    "    print(f\"Most common lenght: {freq_len} ({fd_len[freq_len]} words)\")\n",
    "    print(f\"Lenght proportion {freq_len}: {round(100 * fd_len.freq(freq_len), 2)}%\")\n",
    "\n",
    "    short_tokens = [w for w in category if len(w) < freq_len]\n",
    "    print(f\"Tokens with length < {freq_len}: {short_tokens[:10]}\")\n",
    "\n",
    "    common_tokens = [w for w in category if len(w) == freq_len]\n",
    "    print(f\"Tokens with length == {freq_len}: {common_tokens[:10]}\")\n",
    "\n",
    "    common_tokens = [w for w in category if len(w) > freq_len]\n",
    "    print(f\"Tokens with length > {freq_len}: {common_tokens[:5]}\")\n",
    "\n",
    "    longest_word = max(category, key=len)\n",
    "    print(f\"The longest word is: '{longest_word[:25]}...' with {len(longest_word)} characters.\")\n",
    "\n",
    "    long_words = [w for w in category if len(w) > 20]\n",
    "\n",
    "    fd_long_words = FreqDist(long_words)\n",
    "    print(f\"\\nTotal words longer than 20 characters: {len(long_words)}\")\n",
    "    print(f\"Unique words longer than 20 characters: {len(set(long_words))}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c7215b7db60f21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T09:44:07.919589Z",
     "start_time": "2025-05-19T09:44:07.029270Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the maximum word length to include\n",
    "max_len = 20\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Loop through categories, skipping 'non_toxic'\n",
    "for key, category in categories_norm.items():\n",
    "    if key == 'non_toxic':\n",
    "        continue\n",
    "\n",
    "    fd_len = FreqDist(len(w) for w in category if len(w) <= max_len)\n",
    "    lengths = list(range(1, max_len + 1))\n",
    "    freqs = [fd_len[l] for l in lengths]\n",
    "    plt.plot(lengths, freqs, label=key)\n",
    "\n",
    "# Add labels and legend\n",
    "plt.title(\"Word Length Frequency by Category (excluding 'non_toxic')\")\n",
    "plt.xlabel(\"Word Length (characters)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6956d6fbaac3e770",
   "metadata": {},
   "source": [
    "Most Common Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1238104e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:41:09.648207Z",
     "start_time": "2025-05-19T07:40:26.154480Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus_fdist = nltk.FreqDist(corpus.words())\n",
    "print(corpus_fdist.most_common(10))\n",
    "\n",
    "corpus_norm_fdist = nltk.FreqDist(corpus_norm)\n",
    "print(corpus_norm_fdist.most_common(10))\n",
    "\n",
    "def percentage(count, total):\n",
    "    return 100 * count / total\n",
    "\n",
    "total_words = len(corpus.words())\n",
    "\n",
    "for category in corpus.categories():\n",
    "    words = corpus.words(categories=category)\n",
    "    total = len(words)\n",
    "    fdist = FreqDist(words)\n",
    "    print(f\"\\nTop 5 words in {category}:\")\n",
    "    for word, freq in fdist.most_common(5):\n",
    "        print(f\"{word}: {freq} ({percentage(freq, total):.2f}%)\")\n",
    "\n",
    "for key, category in categories_norm.items():\n",
    "    total = len(category)\n",
    "    fdist = FreqDist(category)\n",
    "    print(f\"\\nTop 5 words in {key} (normalized):\")\n",
    "    for word, freq in fdist.most_common(5):\n",
    "        print(f\"{word}: {freq} ({percentage(freq, total):.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3444bfcc5fe086fe",
   "metadata": {},
   "source": [
    "Most common bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e66b07227e826f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T09:27:58.840066Z",
     "start_time": "2025-05-19T09:27:11.420800Z"
    }
   },
   "outputs": [],
   "source": [
    "# For the entire original corpus\n",
    "corpus_bigrams = list(bigrams(corpus.words()))\n",
    "corpus_bigram_fdist = FreqDist(corpus_bigrams)\n",
    "print(corpus_bigram_fdist.most_common(10))\n",
    "\n",
    "# For the entire normalized corpus\n",
    "corpus_norm_bigrams = list(bigrams(corpus_norm))\n",
    "corpus_norm_bigram_fdist = FreqDist(corpus_norm_bigrams)\n",
    "print(corpus_norm_bigram_fdist.most_common(10))\n",
    "\n",
    "# For each category in the original corpus\n",
    "for category in corpus.categories():\n",
    "    words = corpus.words(categories=category)\n",
    "    bigrams_cat = list(bigrams(words))\n",
    "    total = len(bigrams_cat)\n",
    "    fdist = FreqDist(bigrams_cat)\n",
    "    print(f\"\\nTop 5 bigrams in {category}:\")\n",
    "    for bigram, freq in fdist.most_common(5):\n",
    "        print(f\"{bigram}: {freq} ({percentage(freq, total):.2f}%)\")\n",
    "\n",
    "# For each category in the normalized corpus\n",
    "for key, category_words in categories_norm.items():\n",
    "    bigrams_cat = list(bigrams(category_words))\n",
    "    total = len(bigrams_cat)\n",
    "    fdist = FreqDist(bigrams_cat)\n",
    "    print(f\"\\nTop 5 bigrams in {key} (normalized):\")\n",
    "    for bigram, freq in fdist.most_common(5):\n",
    "        print(f\"{bigram}: {freq} ({percentage(freq, total):.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafad3e810bb9c39",
   "metadata": {},
   "source": [
    "Most common words dispersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abcfeb1944d6aa0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T09:23:12.032156Z",
     "start_time": "2025-05-19T09:22:33.075977Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus_fdist = nltk.FreqDist(corpus_norm)\n",
    "\n",
    "top_words = [word for word, freq in corpus_fdist.most_common(10)]\n",
    "\n",
    "nltk.Text(corpus.words()).dispersion_plot(top_words)\n",
    "\n",
    "for key, category in categories_norm.items():\n",
    "    corpus_fdist = nltk.FreqDist(category)\n",
    "\n",
    "    top_words = [word for word, freq in corpus_fdist.most_common(10)]\n",
    "\n",
    "    ax = nltk.Text(corpus.words(categories=key)).dispersion_plot(top_words)\n",
    "    plt.title(f\"Lexical Dispersion Plot for {key}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb915420702c9e4",
   "metadata": {},
   "source": [
    "Uppercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf84f105b5cf08c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T10:02:10.570735Z",
     "start_time": "2025-05-19T10:01:51.298636Z"
    }
   },
   "outputs": [],
   "source": [
    "cfd_upper = ConditionalFreqDist()\n",
    "\n",
    "for category in corpus.categories():\n",
    "    words = corpus.words(categories=category)\n",
    "    total_letters = sum(1 for w in words for c in w if c.isalpha())\n",
    "    uppercase_letters = sum(1 for w in words for c in w if c.isupper())\n",
    "    if total_letters > 0:\n",
    "        percentage_upper = (uppercase_letters / total_letters) * 100\n",
    "        cfd_upper[category]['uppercase_percentage'] = percentage_upper\n",
    "\n",
    "for category in corpus.categories():\n",
    "    print(f\"{category}: {cfd_upper[category]['uppercase_percentage']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae897c4450a13f28",
   "metadata": {},
   "source": [
    "Exclamations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cfe3abec872867",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T14:11:23.131547Z",
     "start_time": "2025-05-19T14:11:22.638637Z"
    }
   },
   "outputs": [],
   "source": [
    "cfd_punct = ConditionalFreqDist()\n",
    "\n",
    "for category in corpus.categories():\n",
    "    text = ' '.join(corpus.words(categories=category))\n",
    "    total_chars = len(text)\n",
    "    excls = text.count('!')\n",
    "    ques = text.count('?')\n",
    "    if total_chars:\n",
    "        cfd_punct[category]['excl_pct'] = excls / total_chars * 100\n",
    "        cfd_punct[category]['ques_pct'] = ques / total_chars * 100\n",
    "\n",
    "for cat in corpus.categories():\n",
    "    print(\n",
    "        f\"{cat}:\\n\"\n",
    "        f\"! : {cfd_punct[cat]['excl_pct']:.2f}%\\n\"\n",
    "        f\"? : {cfd_punct[cat]['ques_pct']:.2f}% \\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f393730a19611db",
   "metadata": {},
   "source": [
    "Repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4147487d8c4cf69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T12:02:43.405216Z",
     "start_time": "2025-05-19T12:02:27.898675Z"
    }
   },
   "outputs": [],
   "source": [
    "cfd_reps = ConditionalFreqDist()\n",
    "\n",
    "for category in corpus.categories():\n",
    "    words = corpus.words(categories=category)\n",
    "    text = ' '.join(words)\n",
    "    total_chars = len(text)\n",
    "    total_words = len(words) or 1\n",
    "\n",
    "    char_reps = len(re.findall(r'(.)\\1{2,}', text))\n",
    "    word_reps = len(re.findall(r'\\b(\\w+)( \\1\\b)+', text.lower()))\n",
    "\n",
    "    cfd_reps[category]['char_reps_pct'] = char_reps / total_chars * 100\n",
    "    cfd_reps[category]['word_reps_pct'] = word_reps / total_words * 100\n",
    "\n",
    "for cat in corpus.categories():\n",
    "    print(\n",
    "        f\"{cat}:\\n\"\n",
    "        f\"char repeats: {cfd_reps[cat]['char_reps_pct']:.2f}% \\n\"\n",
    "        f\"word repeats: {cfd_reps[cat]['word_reps_pct']:.2f}% \\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfb49e39cfadd05",
   "metadata": {},
   "source": [
    "5. Tagging corpus and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd9f98e75f3e1ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T10:55:55.238671Z",
     "start_time": "2025-05-19T10:49:20.203346Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenization and POS tagging\n",
    "total_sents = []\n",
    "tagged_sents = []\n",
    "file_to_sent_count = {}\n",
    "\n",
    "for fid in corpus.fileids():\n",
    "    sent_count = 0\n",
    "    for line in corpus.raw(fid).splitlines():\n",
    "        if line.strip():\n",
    "            tokens = word_tokenize(line)\n",
    "            total_sents.append(tokens)\n",
    "            tagged_sents.append(nltk.pos_tag(tokens))\n",
    "            sent_count += 1\n",
    "    file_to_sent_count[fid] = sent_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7ac3f694f5f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tagged corpus in subfolders by category\n",
    "output_dir = 'tagged_corpus'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "offset = 0\n",
    "for category in corpus.categories():\n",
    "    category_dir = os.path.join(output_dir, category)\n",
    "    os.makedirs(category_dir, exist_ok=True)\n",
    "\n",
    "    # Get all files for the current category\n",
    "    fileids = corpus.fileids(categories=[category])\n",
    "    all_comments = []\n",
    "\n",
    "    for fid in fileids:\n",
    "        comments = [c for c in corpus.raw(fid).splitlines() if c.strip()]\n",
    "        all_comments.extend(comments)\n",
    "\n",
    "    # Save combined tagged output for this category\n",
    "    output_file = os.path.join(category_dir, f\"{category}_tagged.txt\")\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for sent in tagged_sents[offset:offset + len(all_comments)]:\n",
    "            f.write(' '.join(f\"{w}/{t}\" for w, t in sent) + '\\n')\n",
    "    offset += len(all_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e929919579d618",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T11:05:10.310104Z",
     "start_time": "2025-05-19T11:05:10.305806Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load corpus\n",
    "tagged_corpus = CategorizedPlaintextCorpusReader(\n",
    "    output_dir,\n",
    "    r'.*\\.txt',\n",
    "    cat_pattern=r\"([^/.]+)/.*\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a269e9284edf3c5e",
   "metadata": {},
   "source": [
    "Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ca0b76a45cb9a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T11:42:30.404561Z",
     "start_time": "2025-05-19T11:42:17.682123Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "negative_adjectives = {\"bad\", \"satanistic\", \"antisemmitian\", \"racist\", \"evil\", \"nasty\", \"ugly\", \"fat\", \"nazi\", \"nigger\", \"jew\", \"gay\"}\n",
    "mode_adverb_check = lambda w: w.endswith(\"ly\")\n",
    "\n",
    "\n",
    "pos_summary = defaultdict(Counter)\n",
    "specific_summary = defaultdict(Counter)\n",
    "\n",
    "\n",
    "for category in tagged_corpus.categories():\n",
    "    for fileid in tagged_corpus.fileids(categories=[category]):\n",
    "\n",
    "        words_tags = [tuple(token.rsplit(\"/\", 1)) for token in tagged_corpus.raw(fileid).split()]\n",
    "\n",
    "        for word, tag in words_tags:\n",
    "            word_lower = word.lower()\n",
    "\n",
    "            if tag.startswith(\"NN\"):\n",
    "                pos_summary[category][\"Noun\"] += 1\n",
    "            elif tag.startswith(\"VB\"):\n",
    "                pos_summary[category][\"Verb\"] += 1\n",
    "                if tag == \"VB\":\n",
    "                    specific_summary[category][\"Imperative Verbs\"] += 1\n",
    "            elif tag.startswith(\"JJ\"):\n",
    "                pos_summary[category][\"Adjective\"] += 1\n",
    "                if word_lower in negative_adjectives:\n",
    "                    specific_summary[category][\"Negative Adjectives\"] += 1\n",
    "            elif tag.startswith(\"RB\"):\n",
    "                pos_summary[category][\"Adverb\"] += 1\n",
    "                if mode_adverb_check(word_lower):\n",
    "                    specific_summary[category][\"Manner Adverbs\"] += 1\n",
    "            elif tag in {\"PRP\", \"PRP$\", \"WP\", \"WP$\"}:\n",
    "                pos_summary[category][\"Pronoun\"] += 1\n",
    "\n",
    "df_pos = pd.DataFrame(pos_summary).T.fillna(0)\n",
    "df_pos_percent = df_pos.div(df_pos.sum(axis=1), axis=0) * 100\n",
    "\n",
    "\n",
    "relevant_totals = df_pos[\"Verb\"] + df_pos[\"Adjective\"] + df_pos[\"Adverb\"]\n",
    "df_specific = pd.DataFrame(specific_summary).T.fillna(0)\n",
    "df_specific_percent = df_specific.div(relevant_totals, axis=0) * 100\n",
    "\n",
    "\n",
    "print(\"POS distribution (%) by category:\")\n",
    "display(df_pos_percent.round(2))\n",
    "\n",
    "print(\"\\nSpecific features (% of related POS) by category:\")\n",
    "display(df_specific_percent.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0f06c510b8f04e",
   "metadata": {},
   "source": [
    "Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69ad2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(train_path):\n",
    "    df_train = pd.read_csv(train_path)\n",
    "\n",
    "    label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "    df_train['non_toxic'] = (df_train[label_cols].sum(axis=1) == 0).astype(int)\n",
    "\n",
    "    return df_train, label_cols + ['non_toxic']\n",
    "\n",
    "df, all_labels = load_data('Dataset/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32212509",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def tokenize_and_clean(text):\n",
    "    tokens = word_tokenize(text.lower()) \n",
    "    words = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    return words\n",
    "\n",
    "global_tokens = []\n",
    "for text in df['comment_text'].dropna():\n",
    "    global_tokens.extend(tokenize_and_clean(text))\n",
    "\n",
    "global_fdist = FreqDist(global_tokens)\n",
    "global_top_words = [w for w, _ in global_fdist.most_common(10)]\n",
    "\n",
    "global_bigrams = list(bigrams(global_tokens))\n",
    "global_bigram_fdist = FreqDist(global_bigrams)\n",
    "global_top_bigrams = [bg for bg, _ in global_bigram_fdist.most_common(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d78ffc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_length_features(text):\n",
    "    tokens = tokenize_and_clean(text)\n",
    "    lengths = [len(w) for w in tokens]\n",
    "    fd = FreqDist(lengths)\n",
    "    if not lengths:\n",
    "        return {\n",
    "            'most_common_len': 0,\n",
    "            'most_common_freq': 0,\n",
    "            'most_common_prop': 0.0,\n",
    "            'short_count': 0,\n",
    "            'long_count': 0\n",
    "        }\n",
    "\n",
    "    mc_len = fd.max()\n",
    "    mc_freq = fd[mc_len]\n",
    "    mc_prop = mc_freq / len(lengths) * 100\n",
    "\n",
    "    short_count = sum(1 for l in lengths if l < mc_len)\n",
    "    long_count = sum(1 for l in lengths if l > mc_len)\n",
    "    return {\n",
    "        'most_common_len': mc_len,\n",
    "        'most_common_freq': mc_freq,\n",
    "        'most_common_prop': mc_prop,\n",
    "        'short_count': short_count,\n",
    "        'long_count': long_count\n",
    "    }\n",
    "\n",
    "def extract_common_word_features(text):\n",
    "    tokens = tokenize_and_clean(text)\n",
    "    feats = {}\n",
    "    total = len(tokens) or 1\n",
    "    for word in global_top_words:\n",
    "        count = tokens.count(word)\n",
    "        feats[f'count_{word}'] = count\n",
    "        feats[f'prop_{word}'] = count / total * 100\n",
    "    return feats\n",
    "\n",
    "def extract_bigram_features(text):\n",
    "    tokens = tokenize_and_clean(text)\n",
    "    bigrams_text = list(bigrams(tokens))\n",
    "    feats = {}\n",
    "    total = len(bigrams_text) or 1\n",
    "    for bg in global_top_bigrams:\n",
    "        count = bigrams_text.count(bg)\n",
    "        key = f\"bigram_{bg[0]}_{bg[1]}\"\n",
    "        feats[f'{key}_count'] = count\n",
    "        feats[f'{key}_prop'] = count / total * 100\n",
    "    return feats\n",
    "\n",
    "def extract_uppercase_features(text):\n",
    "    letters = [c for c in text if c.isalpha()]\n",
    "    uppers = [c for c in letters if c.isupper()]\n",
    "    pct_upper = (len(uppers) / len(letters) * 100) if letters else 0.0\n",
    "    return {'uppercase_pct': pct_upper}\n",
    "\n",
    "def extract_punctuation_features(text):\n",
    "    total_chars = len(text) or 1\n",
    "    excl = text.count('!')\n",
    "    ques = text.count('?')\n",
    "    return {'excl_pct': excl / total_chars * 100, 'ques_pct': ques / total_chars * 100}\n",
    "\n",
    "def extract_repetition_features(text):\n",
    "    tokens = tokenize_and_clean(text)\n",
    "    text_joined = ' '.join(tokens)\n",
    "    total_chars = len(text_joined) or 1\n",
    "    total_words = len(tokens) or 1\n",
    "    char_reps = len(re.findall(r'(.)\\1{2,}', text_joined))\n",
    "    word_reps = len(re.findall(r'\\b(\\w+)( \\1\\b)+', text_joined.lower()))\n",
    "    return {'char_reps_pct': char_reps / total_chars * 100, 'word_reps_pct': word_reps / total_words * 100}\n",
    "\n",
    "negative_adjectives = {\"bad\", \"satanistic\", \"antisemmitian\", \"racist\", \"evil\", \"nasty\", \"ugly\", \"fat\", \"nazi\", \"nigger\", \"jew\", \"gay\"}\n",
    "mode_adverb_check = lambda w: w.endswith(\"ly\")\n",
    "\n",
    "def extract_pos_features(text):\n",
    "    tokens = tokenize_and_clean(text)\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    counts = Counter()\n",
    "    for word, tag in tags:\n",
    "        if tag.startswith(\"NN\"): counts['noun_count'] += 1\n",
    "        elif tag.startswith(\"VB\"):\n",
    "            counts['verb_count'] += 1\n",
    "            if tag == 'VB': counts['imperative_count'] += 1\n",
    "        elif tag.startswith(\"JJ\"):\n",
    "            counts['adj_count'] += 1\n",
    "            if word.lower() in negative_adjectives:\n",
    "                counts['neg_adj_count'] += 1\n",
    "        elif tag.startswith(\"RB\"):\n",
    "            counts['adv_count'] += 1\n",
    "            if mode_adverb_check(word.lower()): counts['manner_adv_count'] += 1\n",
    "        elif tag in {\"PRP\",\"PRP$\",\"WP\",\"WP$\"}:\n",
    "            counts['pronoun_count'] += 1\n",
    "    total_rel = counts['verb_count'] + counts['adj_count'] + counts['adv_count'] or 1\n",
    "\n",
    "    feats = {\n",
    "        'noun_count': counts['noun_count'],\n",
    "        'verb_count': counts['verb_count'],\n",
    "        'adj_count': counts['adj_count'],\n",
    "        'adv_count': counts['adv_count'],\n",
    "        'pronoun_count': counts['pronoun_count'],\n",
    "        'imperative_pct': counts['imperative_count'] / counts['verb_count'] * 100 if counts['verb_count'] else 0.0,\n",
    "        'neg_adj_pct': counts['neg_adj_count'] / counts['adj_count'] * 100 if counts['adj_count'] else 0.0,\n",
    "        'manner_adv_pct': counts['manner_adv_count'] / counts['adv_count'] * 100 if counts['adv_count'] else 0.0\n",
    "    }\n",
    "    return feats\n",
    "\n",
    "\n",
    "def extract_features(text):\n",
    "    feats = {}\n",
    "    feats.update(extract_length_features(text))\n",
    "    feats.update(extract_common_word_features(text))\n",
    "    feats.update(extract_bigram_features(text))\n",
    "    feats.update(extract_uppercase_features(text))\n",
    "    feats.update(extract_punctuation_features(text))\n",
    "    feats.update(extract_repetition_features(text))\n",
    "    feats.update(extract_pos_features(text))\n",
    "    return feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dfae74",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled = []\n",
    "for _, row in df[['comment_text'] + all_labels].dropna().iterrows():\n",
    "    text = row['comment_text']\n",
    "    for lbl in all_labels:\n",
    "        if row[lbl] == 1:\n",
    "            feats = extract_features(text)\n",
    "            labeled.append((feats, lbl))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dcb0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [lbl for _, lbl in labeled]\n",
    "train_set, test_set = train_test_split(labeled, test_size=0.2, random_state=42, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8864cf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = NaiveBayesClassifier.train(train_set)\n",
    "print(\"Accuracy:\", classify.accuracy(clf, test_set))\n",
    "print(\"Most informative features:\")\n",
    "clf.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a92e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = [lbl for _, lbl in test_set]\n",
    "pred = [clf.classify(feats) for feats, _ in test_set]\n",
    "print(ConfusionMatrix(ref, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0292cb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = [(true, pred) for (feats, true), pred in zip(test_set, pred) if true != pred]\n",
    "print(f\"Total errores: {len(errors)}\")\n",
    "print(\"5 primeros errores:\")\n",
    "for true, pred in errors[:5]:\n",
    "    print(f\"True: {true}, Pred: {pred}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "23f8f943311f5529233f86046d23235be0d71eeae2626731c3a4ba48d4472f24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
